flume1.sources = nginx
flume1.sinks = kafka
flume1.channels = channel
flume1.sources.nginx.channels = channel
flume1.sinks.kafka.channel = channel

# source nginx
flume1.sources.nginx.channels = channel
flume1.sources.nginx.type = taildir
flume1.sources.nginx.positionFile = $FLUME_DATA_DIR/taildir_position.json
flume1.sources.nginx.filegroups = f1
# .../nginx/log/access-.*log
flume1.sources.nginx.filegroups.f1 = NGINX_LOG_PATH
flume1.sources.nginx.headers.f1.headerKey = access
flume1.sources.nginx.fileHeader = true

# sink kafka
flume1.sinks.kafka.type = org.apache.flume.sink.kafka.KafkaSink
flume1.sinks.kafka.brokerList = $BROKER_LIST
flume1.sinks.kafka.topic = $TOPIC
flume1.sinks.kafka.serializer.class = kafka.serializer.StringEncoder

# channel channel
flume1.channels.channel.type = file
flume1.channels.channel.dataDirs = $FLUME_DATA_DIR/data
flume1.channels.channel.useDualCheckpoints = true
flume1.channels.channel.checkpointDir = $FLUME_DATA_DIR/checkpoint1
flume1.channels.channel.backupCheckpointDir = $FLUME_DATA_DIR/checkpoint2
flume1.channels.channel.capacity = 3000000
flume1.channels.channel.transactionCapacity = 5000
# 500M
flume1.channels.channel.maxFileSize = 524288000
flume1.channels.channel.checkpointInterval = 10000
